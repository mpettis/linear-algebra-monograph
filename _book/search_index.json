[["index.html", "Linear Algebra: An Intuitionist Approach Chapter 1 Preface", " Linear Algebra: An Intuitionist Approach Matt Pettis 2021-11-04 Chapter 1 Preface And you may ask yourself, What is that beautiful house? And you may ask yourself, Where does that highway go to? And you may ask yourself, Am I right? Am I wrong? And you may say to yourself, My God! What have I done?  Talking Heads, Once in a Lifetime What one fool can do, another can.  Ancient Simian Proverb  Sylvanus Thompson, Calculus Made Easy Everything is the way it is because it got that way.  DArcy Wentworth Thompson Id like to say Im writing this for the democratization of science and math, but really, for my kids and their friends so that they dont get snookered into thinking this stuff is beyond them and therefore not for them. It is for you. It is everybodys birthright. One of the best things about science, but one Ive found least talked about in the classes that I took in high school and college, is the part that explains why do we think things work this way? Why do we believe things are made up of atoms? Why did people believe that without the ability to see atoms? What is it about the technology weve built that confirms that things are made of atoms? We believe things like this because we concocted hypotheses and made experimental tests that ruthlessly and cumulatively. We make assumptions that are verifiably true, and then we reach a little further with logic and some more subtle observations, and extend the things we get to conclude, and what we have to throw away. That is a powerful process. Somewhere along the way, math got divorced from that process. It wasnt helped by great mathematicians like Carl Gauss who called Number Theory the Queen of Mathematics mostly because it didnt have much in the way of application, and that was a good thing. Or the eminent mathematician G. H. Hardy, who said, I have never done anythinguseful. No discovery of mine has made, or is likely to make, directly or indirectly, for good or ill, the least difference to the amenity of the world. The perspective was, and often is, that math is a thing more akin to art, like poetry, and though it is sometimes useful, its main value is in that it is beautiful and fun. Ironically, his favorite subject, number theory, is the foundation of our ability to transmit secrets safely on the internet, and does, in fact, probably cause more good and ill than he was comfortable with. The downside of such a perspective is that it makes it seem like learning the discipline of mathematics is inscrutable. When you encounter mathematical definitions, such as, What makes a thing a vector space? or What makes a thing a group? or What makes a set measureable? what you read are a bunch of seemingly awkward little statements that seem either indecipherable, or unknowable, or so stupidly dead-simple as to make you wonder why one would even need to say such a thing. For instance, when we get to the definition of a vector space, youll see this as a defining characteristic that your, uh, well call a thingy for now, needs to have to be called a vector space: \\[ (\\vec{x} + \\vec{y}) + \\vec{z} = \\vec{x} + (\\vec{y} + \\vec{z}) \\] For those familiar with how numbers work, this seems like something Captain Obvious would say about math. It could also make you wonder whats the point of saying such a thing? These definitions dont come in an inspiration, like Athena springing fully formed from the forehead of Zeus. When you study the history of mathematics, youll see that when trying to come up with descriptions like this, mathematicians will often argue, and even disagree violently. Youll often see different characterizations like this depending on where you look, because originators disagreed on what was fundamental about what was going on. For systems to be compatible, though, the fundamental assumptions of one camp need to be at least derivable from the other, and vice versa. This monograph is intended give you the motivations of why linear algebra is the way it is. It will address: Where do those rules about a vector space come from? Whats the big deal about linear independence? What would make you come up with an idea like an inner product? Whats helpful about orthogonality? Eigenvectors: how do they even work? Ill approach this as science would ideally approach this. What do we observe? What sort of simplifications can we make to help us understand what is going on? What sort of models help us understand the important parts? "],["well-how-did-i-get-here.html", "Chapter 2 Well, How Did I Get Here?", " Chapter 2 Well, How Did I Get Here? At this point, if you are reading this as opposed to an intro to linear algebra book, I assume the one thing you have is a good familiarity with are the vector spaces of \\(\\mathbb{R}^2\\) and \\(\\mathbb{R}^3\\). These are the vector spaces used extensively in physics and engineering to model things like position, velocity, and forces. You know that you can add two vectors by putting the tail of one vector at the head of the other and connecting the base of one to the tip of the other vector. And we know how to stretch, shrink, and flip a vector, which we do by multiplying a vector by a real number. If you multiply a vector by \\(1/2\\), the length of the vector shrinks to one-half its original length (but the direction doesnt change). If you multiply a vector by \\(3 \\sqrt{2}\\) the magnitude of the result is stretched by that amount. Figure 2.1: Parallelogram Law of Addition Figure 2.2: Vector Scaling These are the prototypical vector spaces, one Id argue 99 times out of 100 people imagine if they know what a vector space is already. If that was all that vector spaces were, mathematicians probably wouldnt make the seemingly awkward definition that are always presented in the first three pages of any textbook: From Wikipedia: Figure 2.3: [Record scratch] Yep, thats me, Vector Space, spewing a lot of incomprehensible stuff. But I wasnt always like this. Let me tell you a story It is a bad way to start, because you really have no frame of reference for what any of the terms mean. It is frustrating and made me angry We shouldnt really start here. This reminds me of the joke about a cab driver driving around the Seattle area in a fog, and he asks a guy coming out of a building if he can tell the cabbie where he is. The guy looks at him and says, Youre in a cab, and walks on. The cabbie says Perfect, I know where I am. The fare asks him how he can figure out anything from what the guy outside said, and the cabbie say, Well, he told me something that was completely true and completely useless. So this must be the Microsoft building. Theres so many questions that should be triggered. Like: Why so many simple axioms? What are vectors, really? What is a field, really? What does it mean to add vectors? What does it mean to multiply a vector by a scalar? How do I know what other vector \\(a \\cdot \\vec{u}\\) becomes? It looks like the scalar field talks about how scalar addition and scalar multiplication works. But vectors only talk about vector addition. Whats up with that? We know from \\(\\mathbb{R}^2\\) and \\(\\mathbb{R}^3\\) how vector spaces works, and we can look over the axioms and confirm that yep, those vector spaces meet the axioms. But that doesnt answer why we lay out the axioms that way. Even more, we dont have a good idea of what other structures my meet these axioms and be a vector space. Or how to interpret that. Lets view the axioms in light of what we know about the \\(\\mathbb{R}\\) spaces: Vectors work the way you think they should, it kinda-sorta works like addition for regular numbers. Scalar multiplication works the way you think it should, it kinda-sorta works like addition and multiplication for regular numbers. Scalars have both addition and multiplication, while vectors only have addition. Thats gotta mean something. Lets further focus on scalar multiplication. In the \\(\\mathbb{R}\\) spaces, we intuitively know when you pick a scalar to multiply a vector by, you are stretching one vector into another, both vectors being same direction. Another, more abstract way of thinking about this (and one that will be useful in the near future!) is that a scalar is a function that takes one vector to another one. With our vector spaces, its easy to see which one: if the scalar is \\(2\\), it maps the vector to the one that is twice its magnitude in the same direction. But theres more to these scalars. If you think of them as functions, per the axioms, adding two scalars will get you to a new scalar that will map vectors. if \\(\\alpha = \\alpha_{1} + \\alpha_{2}\\) is your new scalar, and you operate on \\(\\vec{x}\\), it will work the same was if you operated on \\(\\vec{x}\\) with \\(\\alpha_{1}\\) and \\(\\alpha_{2}\\), and then added those two vectors together. That is, \\(\\alpha \\vec{x} = \\alpha_{1} \\vec{x} + \\alpha_{2} \\vec{x}\\). This is a strong constraint on any function that moves vectors around  that you can combine the scalars first and apply the operation, or apply the constituent scalars individually to \\(\\vec{x}\\) and use the vector \\(+\\) operation to combine the individual applications. This is the property claimed by the last axiom above. We can go through the other axioms and make similar arguments for them, and make similar observations, each putting very strong constraints on how scalar multiplication and vector addition actually construct new vectors. We really filter out a lot of functions that scalar multiplication and vector addition could potentially use in the vector space with these axioms. The rules are really restrictive. The point here is this: we have a good intuitive idea of how vectors behave in \\(\\mathbb{R}\\) spaces. As we stated above, we can just follow our noses: scalars can be added and multiplied, vectors can be added, and we can put them together in ways such that if we construct a vector \\(\\vec{x} = \\alpha_{1} \\vec{x_{1}} + \\alpha_{2} \\vec{x_{2}}\\), we can figure out exactly what vector \\(\\vec{x}\\) we must have. But we dont have to rely on that geometry of arrows in general, and how they stretch and add with the parralelogram rule. We dont have to have any idea what the elements of the vector space really look like (as in, they dont have to be arrows in \\(\\mathbb{R}\\) space). They just have to be objects that have a vector \\(+\\) structure, and you can define some maps on those objects, which you can label with scalars (from \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\), as well see), and they just have to obey the axioms. We will need to lift off from this \\(\\mathbb{R}\\) prototype of vector spaces for some of the vector spaces we will use in quantum theory. At first, you will want to use your intuition about \\(\\mathbb{R}\\) to reason about these more abstract vector spaces (the quantum state space), but it wont quite work, and youll need this more sophisticated abstraction. In the next chapter, well take some quantum phenomenon, and figure out how we pick linear algebra to model our phenomenon, and what tools from its toolbox we will need. And illuminate a little more how linear algebra hangs together. "],["how-do-i-work-this.html", "Chapter 3 How do I work this? 3.1 Lay of the Land 3.2 What things do we need to model this?", " Chapter 3 How do I work this? My uncle tells the story of how they help transition mechanical engineers fresh out of school to working in industry. A senior engineer tasks them with a simple task: a near complete machine needs a piece  it is missing a cog. The tell the new engineer to get them one. The new engineer studies the plans, designs the cog, painstakingly laying out the CAD designs for it, and comes back to the senior engineer after a week with his work to review how to machine that part, and how much it will cost. The senior engineer looks it over, says it is the right piece, and pulls out a catalog, and shows him how much it will cost to buy, usually at a fraction of the cost. The lesson they learn: dont create from scratch stuff you can buy cheaply from a catalog. We might think of physics and mathematics having a similar relationship. Often, as you painstakingly observe a physical system, you figure out what are the important bits you need to capture with a model, and how those bits behave in the system. Then, you go shopping to your local math department, describing what you are doing, and hope that a mathematician can recommend a system theyve already investigated that you can map your problem into, and take advantage of the notions, the notations, and theorems about the system behavior that theyve already come up with. So, lets proceed by looking at a simple spin-\\(1/2\\) system, of electrons that can have either a spin up or down measurement, depending on how the spin-detector is oriented. Many newer books start their quantum discussion this way, and two I can recommend that do this are Quantum Mechanics: The Theoretical Minimum by Len Susskind and Quantum Mechanics: A Paradigms Approach by David McIntyre. I wont repeat their treatment here, and will assume you know the basics of measuring spins in those systems. I will talk about how you start to pick your mathematics from the catalog to model this phenomenon. 3.1 Lay of the Land Here is a picture that captures some of the important information about a quantum experiment we run: Figure 3.1: Two-spin experiment, McIntire Some notes on the picture: The apparatus on the left emits electrons, which have a spin we want to measure. The detectors are labeled with a Z or X to tell you which direction in space we are orienting the detector. We pick the directions arbitrarily, but Z and X are orthogonal directions. The arrows on the detectors indicate which spin orientation an electron comes out of. If it is measured with a spin up, relative to the how the detector is oriented, it exits from the top port, with the up arrow. If down, it exits from the lower port. The labels |+&gt; and |-&gt; are also labels for the spins. The indicate absolute directions of the spin (spin up or down in the Z direction), rather than the up and down arrows on the port, that indicate if the spin is up or down relative to the how the port is oriented, in the Z or X direction. The labels |+&gt;_x and |-&gt;_x represent the absolute spin up/down orientations, but for the X direction. Again, the detector can be reoriented, but if the electron has one of these labels, it is independent of how the detector is oriented. The numbers and shaded bars represent a percentage of electrons that end up in that bucket or state over a large number of electrons entering the system. Like a histogram. Here are some things you, the experimenter, observe about the system: In (a), if you measure the Z spin, then the X spin, then the second time you measure the Z spin, it will be 50-50 up/down. In (b), it just tells you that the same thing happens, no matter if the secon measurement for X is up or down, like in experiment (a). In (c), somthing really weird happens: If you put the X spin detector in the middle, but carefully recombine both beams, as if you didnt measure the X spin, then the Z spin will be as if you didnt measure X spin at all, and stays in the spin state you measured it in in the first detector. That can stand as the first of many weirdnesses you encounter in quantum. As McIntyre says: going from (a) or (b) to (c), its as if you are in a half-lit room, throw open a window shade, and the whole room goes dark. In a classical model, (c) would still have a 50-50 split of spin measurements, but that doesnt happen in the quantum world. 3.2 What things do we need to model this? So, we make the following observations. If we measure a spin as up in the Z direction, and keep measuring the spin with detectors all pointed along the same Z axis, we will always get the same spin up measurement. That is true as long as we dont orient the detector in a different direction. Focusing on Z measurements, we have two states: spin up (|+&gt;) and spin down (|-&gt;). We get that with the detector registering a +1 or -1. If we measure a Z spin with a detector, and it registers a +1, we call it spin up, and take a second, identical detector, and flip it upside, it will register a -1. This scenario is not pictured. If we take a Z detector and measure a spin up electron, and then take a second detector, and start to slightly tilt the detector away from a straight Z orientation, we still only measure +1 and -1 readings. For a slight tilt, almost all electrons will measure spin up, and a few spin down. As it rotates to be perpendicular to the Z direction, electrons measure +1 and -1 with a 50% probability. As we get closer to the tilt making the detector upside down, then most of the electrons will measure -1, until it is exactly upside down, and the detetcor will consistently measure -1. This is kind of weird. Note that if this were a classical spin, you would expect that if you measured a spin of +1, and tilted the detector a little bit, you would measure a value a little less than +1. But quantum doesnt work that way. Instead of reducing the spin a little bit, what happens is that the probability of a +1 starts to decrease as you tilt the detector. The average of multiple measurements approaches the value of what you would expect a single measured spin to decrease by (if it were classical). So, whatever math we come up, it cant be the same classical math that gives a single spin measurement decreasing continuously from +1. It has to be something that accounts for: A spin will always either be +1 or -1 The probability of detecting +1 and -1 change as you tilt the detector. So we go talk to the math department "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
